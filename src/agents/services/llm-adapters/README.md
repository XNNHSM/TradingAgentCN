# LLMé€‚é…å™¨æ¶æ„

åŸºäºPythonç‰ˆæœ¬è®¾è®¡çš„å¯æ‰©å±•LLMé€‚é…å™¨ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡å‹æä¾›å•†ã€‚

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLMServiceV2 (æœåŠ¡ç®¡ç†å™¨)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ å¤šæä¾›å•†ç®¡ç†     â€¢ é”™è¯¯å¤„ç†å’Œé‡è¯•   â€¢ å¥åº·æ£€æŸ¥å’Œç›‘æ§    â”‚ â”‚
â”‚  â”‚ â€¢ è´Ÿè½½å‡è¡¡å’Œåå¤‡   â€¢ ç»Ÿè®¡å’Œæ—¥å¿—è®°å½•   â€¢ é…ç½®çƒ­æ›´æ–°        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DashScopeAdapterâ”‚ â”‚ OpenAIAdapter   â”‚ â”‚ GeminiAdapter   â”‚
â”‚ (é˜¿é‡Œç™¾ç‚¼)      â”‚ â”‚ (æœªæ¥æ‰©å±•)      â”‚ â”‚ (æœªæ¥æ‰©å±•)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DashScope     â”‚ â”‚   OpenAI API    â”‚ â”‚   Google AI     â”‚
â”‚   API           â”‚ â”‚                 â”‚ â”‚   Studio        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ è®¾è®¡ç‰¹æ€§

### 1. å¯æ‰©å±•æ¶æ„
- **åŸºç¡€é€‚é…å™¨æŠ½è±¡**: `BaseLLMAdapter` å®šä¹‰äº†ç»Ÿä¸€æ¥å£
- **æ’ä»¶å¼è®¾è®¡**: æ–°é€‚é…å™¨åªéœ€ç»§æ‰¿åŸºç±»å³å¯é›†æˆ
- **é…ç½®é©±åŠ¨**: é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶è¡Œä¸º

### 2. é«˜å¯ç”¨æ€§
- **ä¸»å¤‡åˆ‡æ¢**: ä¸»æä¾›å•†å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨
- **å¥åº·æ£€æŸ¥**: å®šæœŸæ£€æŸ¥æä¾›å•†å¯ç”¨æ€§
- **é‡è¯•æœºåˆ¶**: æ”¯æŒæŒ‡æ•°é€€é¿é‡è¯•

### 3. å®Œæ•´ç›‘æ§
- **ç»Ÿè®¡ä¿¡æ¯**: è¯·æ±‚æ¬¡æ•°ã€æˆåŠŸç‡ã€å¹³å‡å“åº”æ—¶é—´
- **è¯¦ç»†æ—¥å¿—**: ç»“æ„åŒ–æ—¥å¿—ï¼Œä¾¿äºç›‘æ§å’Œè°ƒè¯•
- **æˆæœ¬è¿½è¸ª**: è‡ªåŠ¨è®¡ç®—Tokenä½¿ç”¨æˆæœ¬

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```typescript
import { LLMServiceV2 } from './llm-adapters';

// æ³¨å…¥æœåŠ¡
constructor(private readonly llmService: LLMServiceV2) {}

// ç®€å•æ–‡æœ¬ç”Ÿæˆ
const response = await this.llmService.generate("ä½ å¥½ï¼Œä¸–ç•Œï¼", {
  model: "qwen-plus",
  temperature: 0.7,
  maxTokens: 100,
});

// è¯¦ç»†å“åº”ï¼ˆåŒ…å«ä½¿ç”¨ç»Ÿè®¡ï¼‰
const detailResponse = await this.llmService.generateWithDetails("åˆ†æè‚¡ç¥¨", {
  model: "qwen-max",
  temperature: 0.6,
  maxTokens: 2000,
});

console.log(`ç”¨äº† ${detailResponse.usage?.totalTokens} ä¸ªtoken`);
console.log(`æˆæœ¬: $${detailResponse.usage?.cost}`);
```

### 2. å·¥å…·è°ƒç”¨ (Function Calling)

```typescript
const tools = [
  {
    type: "function" as const,
    function: {
      name: "get_stock_data",
      description: "è·å–è‚¡ç¥¨æ•°æ®",
      parameters: {
        type: "object",
        properties: {
          symbol: { type: "string", description: "è‚¡ç¥¨ä»£ç " },
          days: { type: "number", description: "å¤©æ•°" }
        },
        required: ["symbol"]
      }
    }
  }
];

const response = await this.llmService.generateWithDetails(
  "å¸®æˆ‘åˆ†æå¹³å®‰é“¶è¡Œ(000001)æœ€è¿‘çš„è¡¨ç°", 
  {
    model: "qwen-plus",
    tools,
    toolChoice: "auto"
  }
);

if (response.toolCalls) {
  console.log("æ¨¡å‹æƒ³è°ƒç”¨å·¥å…·:", response.toolCalls);
}
```

### 3. æ‰¹é‡å¤„ç†

```typescript
const prompts = [
  "åˆ†æè‹¹æœå…¬å¸",
  "åˆ†æç‰¹æ–¯æ‹‰",
  "åˆ†æå¾®è½¯"
];

const responses = await this.llmService.generateBatch(prompts, {
  model: "qwen-turbo",
  concurrency: 3, // å¹¶å‘æ•°
  maxTokens: 500
});

responses.forEach((response, index) => {
  console.log(`${prompts[index]}: ${response.content}`);
});
```

## ğŸ› ï¸ é…ç½®

### ç¯å¢ƒå˜é‡

```bash
# åŸºç¡€é…ç½®
LLM_PRIMARY_PROVIDER=dashscope          # ä¸»æä¾›å•†
LLM_FALLBACK_PROVIDERS=openai,gemini    # å¤‡ç”¨æä¾›å•†ï¼ˆé€—å·åˆ†éš”ï¼‰
LLM_ENABLE_FALLBACK=true                # å¯ç”¨å¤‡ç”¨åˆ‡æ¢
LLM_MAX_RETRIES=3                       # æœ€å¤§é‡è¯•æ¬¡æ•°
LLM_RETRY_DELAY=1000                    # é‡è¯•å»¶è¿Ÿ(ms)
LLM_HEALTH_CHECK_INTERVAL=300000        # å¥åº·æ£€æŸ¥é—´éš”(ms)

# DashScopeé…ç½®
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxx       # APIå¯†é’¥
DASHSCOPE_BASE_URL=https://...          # APIåŸºç¡€URL(å¯é€‰)
DASHSCOPE_STANDARD_MODEL=qwen-plus      # é»˜è®¤æ¨¡å‹
```

### ä»£ç é…ç½®

```typescript
// åœ¨agents.module.tsä¸­é…ç½®
@Module({
  providers: [
    DashScopeAdapter,
    // OpenAIAdapter,    // æœªæ¥æ·»åŠ 
    // GeminiAdapter,    // æœªæ¥æ·»åŠ 
    LLMServiceV2,
  ],
})
export class AgentsModule {}
```

## ğŸ“Š ç›‘æ§å’Œç»Ÿè®¡

### 1. æœåŠ¡çŠ¶æ€

```typescript
// è·å–æ•´ä½“ç»Ÿè®¡
const stats = this.llmService.getServiceStats();
console.log(stats);
// {
//   totalAdapters: 1,
//   availableAdapters: 1,
//   primaryProvider: "dashscope",
//   fallbackEnabled: true
// }

// è·å–æä¾›å•†è¯¦ç»†çŠ¶æ€
const providerStatus = this.llmService.getProviderStatus();
providerStatus.forEach(status => {
  console.log(`${status.name}: ${status.available ? 'å¯ç”¨' : 'ä¸å¯ç”¨'}`);
  console.log(`æˆåŠŸç‡: ${(1 - status.totalFailures/status.totalRequests) * 100}%`);
  console.log(`å¹³å‡å“åº”æ—¶é—´: ${status.averageResponseTime}ms`);
});
```

### 2. å¥åº·æ£€æŸ¥

```typescript
// æ‰‹åŠ¨è§¦å‘å¥åº·æ£€æŸ¥
const healthResults = await this.llmService.triggerHealthCheck();
healthResults.forEach((healthy, provider) => {
  console.log(`${provider}: ${healthy ? 'å¥åº·' : 'å¼‚å¸¸'}`);
});
```

### 3. æˆæœ¬ç›‘æ§

```typescript
// è·å–æ”¯æŒçš„æ¨¡å‹å’Œå®šä»·
const allModels = this.llmService.getAllSupportedModels();
allModels.forEach((models, provider) => {
  models.forEach(model => {
    console.log(`${provider}/${model.name}: $${model.costPer1kInputTokens}/1k input tokens`);
  });
});
```

## ğŸ”§ æ·»åŠ æ–°çš„é€‚é…å™¨

### 1. åˆ›å»ºé€‚é…å™¨ç±»

```typescript
// src/agents/services/llm-adapters/openai-adapter.ts
import { BaseLLMAdapter } from './base-llm-adapter';

export class OpenAIAdapter extends BaseLLMAdapter {
  constructor(private readonly configService: ConfigService) {
    super("openai");
  }

  async initialize(): Promise<void> {
    // åˆå§‹åŒ–é€»è¾‘
  }

  isAvailable(): boolean {
    // æ£€æŸ¥APIå¯†é’¥ç­‰
    return !!this.apiKey;
  }

  async generateWithDetails(
    prompt: string | LLMMessage[],
    config?: LLMConfig,
  ): Promise<LLMResponse> {
    // å®ç°OpenAI APIè°ƒç”¨
  }

  getSupportedModels(): ModelInfo[] {
    return [
      {
        name: "gpt-4",
        description: "GPT-4",
        contextLength: 8192,
        supportsFunctionCalling: true,
        costPer1kInputTokens: 0.03,
        costPer1kOutputTokens: 0.06,
        recommendedFor: ["å¤æ‚æ¨ç†", "ä»£ç ç”Ÿæˆ"]
      }
    ];
  }

  getDefaultModel(): string {
    return "gpt-4";
  }
}
```

### 2. æ³¨å†Œé€‚é…å™¨

```typescript
// src/agents/services/llm-adapters/llm-service-v2.ts
constructor(
  private readonly dashScopeAdapter: DashScopeAdapter,
  private readonly openaiAdapter: OpenAIAdapter, // æ·»åŠ æ–°é€‚é…å™¨
) {
  this.loadConfiguration();
}

private async initializeAdapters(): Promise<void> {
  const adapters = [
    this.dashScopeAdapter,
    this.openaiAdapter, // æ³¨å†Œæ–°é€‚é…å™¨
  ];
  // ...
}
```

### 3. æ›´æ–°æ¨¡å—é…ç½®

```typescript
// src/agents/agents.module.ts
@Module({
  providers: [
    DashScopeAdapter,
    OpenAIAdapter, // æ·»åŠ åˆ°providers
    LLMServiceV2,
  ],
})
export class AgentsModule {}
```

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•

```bash
# æµ‹è¯•ç‰¹å®šé€‚é…å™¨
npm test -- --testPathPattern="dashscope-adapter.spec.ts"

# æµ‹è¯•é›†æˆåŠŸèƒ½
npm test -- --testPathPattern="llm-integration.spec.ts"
```

### æ€§èƒ½æµ‹è¯•

```typescript
// æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½
const startTime = Date.now();
const responses = await llmService.generateBatch(
  Array(10).fill("æµ‹è¯•æ¶ˆæ¯"),
  { concurrency: 5 }
);
console.log(`æ‰¹é‡å¤„ç†è€—æ—¶: ${Date.now() - startTime}ms`);
```

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

1. **é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥**
   ```
   æ£€æŸ¥: APIå¯†é’¥é…ç½®ã€ç½‘ç»œè¿æ¥ã€æ¨¡å—ä¾èµ–
   ```

2. **æ‰€æœ‰æä¾›å•†ä¸å¯ç”¨**
   ```
   æ£€æŸ¥: å¥åº·æ£€æŸ¥æ—¥å¿—ã€APIé™é¢ã€ç½‘ç»œé—®é¢˜
   ```

3. **å·¥å…·è°ƒç”¨å¤±è´¥**
   ```
   æ£€æŸ¥: å·¥å…·å®šä¹‰æ ¼å¼ã€æ¨¡å‹æ˜¯å¦æ”¯æŒFunction Calling
   ```

4. **æˆæœ¬è¿‡é«˜**
   ```
   æ£€æŸ¥: æ¨¡å‹é€‰æ‹©ã€tokenä½¿ç”¨é‡ã€æ‰¹å¤„ç†ä¼˜åŒ–
   ```

### è°ƒè¯•æŠ€å·§

```typescript
// å¯ç”¨è¯¦ç»†æ—¥å¿—
process.env.LOG_LEVEL = "debug";

// æŸ¥çœ‹æä¾›å•†çŠ¶æ€
console.log(llmService.getProviderStatus());

// æ£€æŸ¥æ¨¡å‹æ”¯æŒ
const models = llmService.getAllSupportedModels();
console.log(models.get("dashscope"));
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. æ¨¡å‹é€‰æ‹©
- **qwen-turbo**: å¿«é€Ÿå“åº”ï¼Œé€‚åˆç®€å•ä»»åŠ¡
- **qwen-plus**: å¹³è¡¡æ€§ä»·æ¯”ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
- **qwen-max**: æœ€å¼ºæ€§èƒ½ï¼Œé€‚åˆå¤æ‚åˆ†æ

### 2. é”™è¯¯å¤„ç†
```typescript
try {
  const response = await llmService.generate(prompt, config);
  return response;
} catch (error) {
  if (error.message.includes("API")) {
    // APIç›¸å…³é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡è¯•æˆ–åˆ‡æ¢æä¾›å•†
    logger.warn("APIè°ƒç”¨å¤±è´¥ï¼Œå·²è‡ªåŠ¨å¤„ç†");
  } else {
    // å…¶ä»–é”™è¯¯ï¼Œéœ€è¦äººå·¥ä»‹å…¥
    logger.error("ç³»ç»Ÿé”™è¯¯", error);
    throw error;
  }
}
```

### 3. æ€§èƒ½ä¼˜åŒ–
- åˆç†è®¾ç½® `maxTokens` æ§åˆ¶æˆæœ¬
- ä½¿ç”¨æ‰¹é‡å¤„ç†æé«˜ååé‡
- é€‰æ‹©åˆé€‚çš„ `temperature` å€¼
- å¯ç”¨ç¼“å­˜å‡å°‘é‡å¤è°ƒç”¨

### 4. ç›‘æ§å‘Šè­¦
```typescript
// è®¾ç½®æˆåŠŸç‡å‘Šè­¦
const status = llmService.getProviderStatus();
status.forEach(provider => {
  const successRate = 1 - (provider.totalFailures / provider.totalRequests);
  if (successRate < 0.95) {
    // å‘é€å‘Šè­¦
    logger.error(`${provider.name} æˆåŠŸç‡è¿‡ä½: ${successRate * 100}%`);
  }
});
```

## ğŸ›£ï¸ å‘å±•è·¯çº¿å›¾

### çŸ­æœŸç›®æ ‡
- [x] DashScopeé€‚é…å™¨å®Œæ•´å®ç°
- [ ] OpenAIé€‚é…å™¨å®ç°
- [ ] Claudeé€‚é…å™¨å®ç°
- [ ] è¯·æ±‚ç¼“å­˜æœºåˆ¶

### ä¸­æœŸç›®æ ‡
- [ ] æµå¼å“åº”æ”¯æŒ
- [ ] å›¾åƒå’Œå¤šæ¨¡æ€æ”¯æŒ
- [ ] æ›´è¯¦ç»†çš„æˆæœ¬åˆ†æ
- [ ] A/Bæµ‹è¯•æ¡†æ¶

### é•¿æœŸç›®æ ‡
- [ ] è‡ªåŠ¨æ¨¡å‹é€‰æ‹©
- [ ] æ™ºèƒ½è´Ÿè½½å‡è¡¡
- [ ] å®æ—¶æ€§èƒ½ä¼˜åŒ–
- [ ] ä¼ä¸šçº§ç®¡æ§å°

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0.0 (2025-08-18)
- ğŸ‰ é¦–æ¬¡å‘å¸ƒå¯æ‰©å±•LLMé€‚é…å™¨æ¶æ„
- âœ… DashScopeé€‚é…å™¨å®Œæ•´å®ç°
- âœ… å¤šæä¾›å•†æ”¯æŒå’Œè‡ªåŠ¨åˆ‡æ¢
- âœ… å¥åº·æ£€æŸ¥å’Œç›‘æ§ç³»ç»Ÿ
- âœ… å®Œæ•´çš„æµ‹è¯•è¦†ç›–

### è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®æ–°çš„é€‚é…å™¨æˆ–åŠŸèƒ½æ”¹è¿›ï¼è¯·ç¡®ä¿ï¼š
1. éµå¾ªç°æœ‰ä»£ç é£æ ¼
2. æ·»åŠ å®Œæ•´çš„å•å…ƒæµ‹è¯•
3. æ›´æ–°ç›¸å…³æ–‡æ¡£
4. æ€§èƒ½æµ‹è¯•é€šè¿‡